[{"title":"k8s高可用集群V1.11.1安装记录","date":"2018-09-13T02:23:54.000Z","path":"2018/09/13/k8s高可用集群V1-11-1安装记录/","text":"实验环境 hostname IP 内存 职责 k8s-vip 192.168.1.110 —— VIP（虚拟IP） k8s-master1 192.168.1.111 4G Master,Keepalived,HAProxy k8s-master2 192.168.1.112 4G Master,Keepalived,HAProxy k8s-master3 192.168.1.113 4G Master,Keepalived,HAProxy k8s-slave1 192.168.1.114 4G Worker k8s-slave1 192.168.1.115 4G Worker 环境准备1. 配置hosts信息（所有节点）12345678cat &lt;&lt;EOF &gt;&gt; /etc/hosts192.168.1.110 k8s-vip192.168.1.111 k8s-master1192.168.1.112 k8s-master2192.168.1.113 k8s-master3192.168.1.114 k8s-slave1192.168.1.115 k8s-slave2EOF 2. 安装Docker （所有节点）安装Docker，步骤略可参考http://www.ebanban.com/?p=496 3. 在所有Master节点上输入以下环境变量，主机名和IP信息根据自己的实际的情况进行修改（#台Master节点）12345678910export KUBECONFIG=/etc/kubernetes/admin.confexport LOAD_BALANCER_DNS=k8s-vipexport LOAD_BALANCER_PORT=8443export CP0_HOSTNAME=k8s-master1export CP1_HOSTNAME=k8s-master2export CP2_HOSTNAME=k8s-master3export VIP_IP=192.168.1.110export CP0_IP=192.168.1.111export CP1_IP=192.168.1.112export CP2_IP=192.168.1.113 4. 关闭防火墙、关闭swap、关闭SELinux、调整内核参数(所有节点)1234567891011sudo systemctl stop firewalldsudo systemctl disable firewalldsudo swapoff -asudo sed -i &apos;/ swap / s/^\\(.*\\)$/#\\1/g&apos; /etc/fstabsudo setenforce 0sed -i &apos;s/SELINUX=permissive/SELINUX=disabled/&apos; /etc/sysconfig/selinuxcat &lt;&lt;EOF &gt; /etc/sysctl.d/k8s.confnet.bridge.bridge-nf-call-ip6tables = 1net.bridge.bridge-nf-call-iptables = 1EOFsysctl --system 5.准备镜像（所有节点）1234567891011121314# 创建脚本加入如下内容#!/bin/bashimages=(kube-proxy-amd64:v1.11.1 kube-scheduler-amd64:v1.11.1 kube-controller-manager-amd64:v1.11.1 kube-apiserver-amd64:v1.11.1etcd-amd64:3.2.18 pause-amd64:3.1 kubernetes-dashboard-amd64:v1.8.3 k8s-dns-sidecar-amd64:1.14.9 k8s-dns-kube-dns-amd64:1.14.9k8s-dns-dnsmasq-nanny-amd64:1.14.9 )for imageName in $&#123;images[@]&#125; ; dodocker pull mirrorgooglecontainers/$imageNamedocker tag mirrorgooglecontainers/$imageName k8s.gcr.io/$imageNamedocker rmi mirrorgooglecontainers/$imageNamedonedocker tag da86e6ba6ca1 k8s.gcr.io/pause:3.1docker pull coredns/coredns:1.1.3docker tag coredns/coredns:1.1.3 k8s.gcr.io/coredns:1.1.3docker rmi coredns/coredns:1.1.3 12345# 添加运行权限chmod -R 777 ./xxx.sh# 执行脚本./xxx.sh 6. 安装、配置kubelet （所有节点）1234567891011cat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo[kubernetes]name=Kubernetesbaseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/enabled=1gpgcheck=1repo_gpgcheck=1gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpgEOFyum install -y kubelet-1.11.1 kubeadm-1.11.1 kubectl-1.11.1systemctl enable kubelet 7.准备SSH Keys（任意Master节点）12345# 生成SSH Key（通常在第一台Master上操作，可以在终端上操作）ssh-keygen -t rsa -b 2048 -f /root/.ssh/id_rsa -N &quot;&quot;# 将SSH Key复制给其他主机for host in &#123;$CP0_HOSTNAME,$CP1_HOSTNAME,$CP2_HOSTNAME&#125;; do ssh-copy-id $host; done $host; done 8. 部署第一个keepalived （第一个Master节点）keepalived用于生产浮动的虚拟IP，并将浮动IP分配给优先级最高且haproxy正常运行的节点在第一台Master上配置和启动keepalived，若网卡名称不为示例中的eth0则改为对应名称 1234567891011121314151617181920212223242526272829303132# 安装 部署第一个keepalivedyum install -y keepalived curl psmisc &amp;&amp; systemctl enable keepalived# 自定义配置cat &lt;&lt; EOF &gt; /etc/keepalived/keepalived.confvrrp_script haproxy-check &#123; script &quot;killall -0 haproxy&quot; interval 2 weight 20&#125; vrrp_instance haproxy-vip &#123; state BACKUP priority 102 interface ens33 virtual_router_id 51 advert_int 3 unicast_src_ip $CP0_IP unicast_peer &#123; $CP1_IP $CP2_IP &#125; virtual_ipaddress &#123; $VIP_IP &#125; track_script &#123; haproxy-check weight 20 &#125;&#125;EOF# 启动 keepalivedsystemctl start keepalived 9. 部署第二个keepalived （第二个Master节点）1234567891011121314151617181920212223242526272829303132# 安装 部署第一个keepalivedyum install -y keepalived curl psmisc &amp;&amp; systemctl enable keepalived# 自定义配置cat &lt;&lt; EOF &gt; /etc/keepalived/keepalived.confvrrp_script haproxy-check &#123; script &quot;killall -0 haproxy&quot; interval 2 weight 20&#125;vrrp_instance haproxy-vip &#123; state BACKUP priority 101 interface ens33 virtual_router_id 51 advert_int 3 unicast_src_ip $CP1_IP unicast_peer &#123; $CP0_IP $CP2_IP &#125; virtual_ipaddress &#123; $VIP_IP &#125; track_script &#123; haproxy-check weight 20 &#125;&#125;EOF# 启动 keepalivedsystemctl start keepalived 10. 部署第三个keepalived （第三个Master节点）1234567891011121314151617181920212223242526272829303132# 安装 部署第一个keepalivedyum install -y keepalived curl psmisc &amp;&amp; systemctl enable keepalived# 自定义配置cat &lt;&lt; EOF &gt; /etc/keepalived/keepalived.confvrrp_script haproxy-check &#123; script &quot;killall -0 haproxy&quot; interval 2 weight 20&#125;vrrp_instance haproxy-vip &#123; state BACKUP priority 100 interface ens33 virtual_router_id 51 advert_int 3 unicast_src_ip $CP2_IP unicast_peer &#123; $CP0_IP $CP1_IP &#125; virtual_ipaddress &#123; $VIP_IP &#125; track_script &#123; haproxy-check weight 20 &#125;&#125;EOF# 启动 keepalivedsystemctl start keepalived 11. 部署HAProxy （所有Master节点）12345678910111213141516171819202122232425262728293031323334353637383940414243# 安装HAproxyyum install -y haproxy &amp;&amp; systemctl enable haproxy# 自定义配置文件cat &lt;&lt; EOF &gt; /etc/haproxy/haproxy.cfgglobal log 127.0.0.1 local0 log 127.0.0.1 local1 notice tune.ssl.default-dh-param 2048defaults log global mode http option dontlognull timeout connect 5000ms timeout client 600000ms timeout server 600000mslisten stats bind :9090 mode http balance stats uri /haproxy_stats stats auth admin:admin stats admin if TRUEfrontend kube-apiserver-https mode tcp bind :8443 default_backend kube-apiserver-backendbackend kube-apiserver-backend mode tcp balance roundrobin stick-table type ip size 200k expire 30m stick on src server k8s-master1 192.168.1.111:6443 check server k8s-master2 192.168.1.112:6443 check server k8s-master3 192.168.1.113:6443 checkEOF# 启动 HAproxysystemctl start haproxy 安装kubernetes1. 配置第一个Master节点（第一个Master节点）1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253cat &gt;kubeadm-master.config&lt;&lt;EOFapiVersion: kubeadm.k8s.io/v1alpha2kind: MasterConfigurationkubernetesVersion: v1.11.1apiServerCertSANs:- &quot;k8s-master1&quot;- &quot;k8s-master2&quot;- &quot;k8s-master3&quot;- &quot;192.168.1.111&quot;- &quot;192.168.1.112&quot;- &quot;192.168.1.113&quot;- &quot;192.168.1.110&quot;- &quot;127.0.0.1&quot;api: advertiseAddress: $CP0_IP controlPlaneEndpoint: 192.168.1.110:8443etcd: local: extraArgs: listen-client-urls: &quot;https://127.0.0.1:2379,https://$CP0_IP:2379&quot; advertise-client-urls: &quot;https://$CP0_IP:2379&quot; listen-peer-urls: &quot;https://$CP0_IP:2380&quot; initial-advertise-peer-urls: &quot;https://$CP0_IP:2380&quot; initial-cluster: &quot;$CP0_HOSTNAME=https://$CP0_IP:2380&quot; serverCertSANs: - $CP0_HOSTNAME - $CP0_IP peerCertSANs: - $CP0_HOSTNAME - $CP0_IPcontrollerManagerExtraArgs: node-monitor-grace-period: 10s pod-eviction-timeout: 10snetworking: podSubnet: 10.244.0.0/16EOF# 初始化# 注意保存返回的 join 命令kubeadm init --config kubeadm-master.config# 打包ca相关文件上传至其他master节点cd /etc/kubernetes &amp;&amp; tar cvzf k8s-key.tgz admin.conf pki/ca.* pki/sa.* pki/front-proxy-ca.* pki/etcd/ca.*scp k8s-key.tgz k8s-master2:~/scp k8s-key.tgz k8s-master3:~/ssh k8s-master2 &apos;tar xf k8s-key.tgz -C /etc/kubernetes/&apos;ssh k8s-master3 &apos;tar xf k8s-key.tgz -C /etc/kubernetes/&apos; 2. 配置第二个Master节点（第二个Master节点）12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758cat &gt;kubeadm-master.config&lt;&lt;EOFapiVersion: kubeadm.k8s.io/v1alpha2kind: MasterConfigurationkubernetesVersion: v1.11.1apiServerCertSANs:- &quot;k8s-master1&quot;- &quot;k8s-master2&quot;- &quot;k8s-master3&quot;- &quot;192.168.1.111&quot;- &quot;192.168.1.112&quot;- &quot;192.168.1.113&quot;- &quot;192.168.1.110&quot;- &quot;127.0.0.1&quot;api: advertiseAddress: $CP1_IP controlPlaneEndpoint: 192.168.1.110:8443etcd: local: extraArgs: listen-client-urls: &quot;https://127.0.0.1:2379,https://$CP1_IP:2379&quot; advertise-client-urls: &quot;https://$CP1_IP:2379&quot; listen-peer-urls: &quot;https://$CP1_IP:2380&quot; initial-advertise-peer-urls: &quot;https://$CP1_IP:2380&quot; initial-cluster: &quot;$CP0_HOSTNAME=https://$CP0_IP:2380,$CP1_HOSTNAME=https://$CP1_IP:2380&quot; initial-cluster-state: existing serverCertSANs: - $CP1_HOSTNAME - $CP1_IP peerCertSANs: - $CP1_HOSTNAME - $CP1_IPcontrollerManagerExtraArgs: node-monitor-grace-period: 10s pod-eviction-timeout: 10snetworking: podSubnet: 10.244.0.0/16EOF# 配置kubeletkubeadm alpha phase certs all --config kubeadm-master.configkubeadm alpha phase kubelet config write-to-disk --config kubeadm-master.configkubeadm alpha phase kubelet write-env-file --config kubeadm-master.configkubeadm alpha phase kubeconfig kubelet --config kubeadm-master.configsystemctl restart kubelet# 添加etcd到集群中KUBECONFIG=/etc/kubernetes/admin.conf kubectl exec -n kube-system etcd-$&#123;CP0_HOSTNAME&#125; -- etcdctl --ca-file /etc/kubernetes/pki/etcd/ca.crt --cert-file /etc/kubernetes/pki/etcd/peer.crt --key-file /etc/kubernetes/pki/etcd/peer.key --endpoints=https://$&#123;CP0_IP&#125;:2379 member add $&#123;CP1_HOSTNAME&#125; https://$&#123;CP1_IP&#125;:2380kubeadm alpha phase etcd local --config kubeadm-master.config# 部署kubeadm alpha phase kubeconfig all --config kubeadm-master.configkubeadm alpha phase controlplane all --config kubeadm-master.configkubeadm alpha phase mark-master --config kubeadm-master.config 3. 部署第三个Master节点 （第三个Master节点）12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758cat &gt;kubeadm-master.config&lt;&lt;EOFapiVersion: kubeadm.k8s.io/v1alpha2kind: MasterConfigurationkubernetesVersion: v1.11.1apiServerCertSANs:- &quot;k8s-master1&quot;- &quot;k8s-master2&quot;- &quot;k8s-master3&quot;- &quot;192.168.1.111&quot;- &quot;192.168.1.112&quot;- &quot;192.168.1.113&quot;- &quot;192.168.1.110&quot;- &quot;127.0.0.1&quot;api: advertiseAddress: $CP2_IP controlPlaneEndpoint: 192.168.1.110:8443etcd: local: extraArgs: listen-client-urls: &quot;https://127.0.0.1:2379,https://$CP2_IP:2379&quot; advertise-client-urls: &quot;https://$CP2_IP:2379&quot; listen-peer-urls: &quot;https://$CP2_IP:2380&quot; initial-advertise-peer-urls: &quot;https://$CP2_IP:2380&quot; initial-cluster: &quot;$CP0_HOSTNAME=https://$CP0_IP:2380,$CP1_HOSTNAME=https://$CP1_IP:2380,$CP2_HOSTNAME=https://$CP2_IP:2380&quot; initial-cluster-state: existing serverCertSANs: - $CP2_HOSTNAME - $CP2_IP peerCertSANs: - $CP2_HOSTNAME - $CP2_IPcontrollerManagerExtraArgs: node-monitor-grace-period: 10s pod-eviction-timeout: 10snetworking: podSubnet: 10.244.0.0/16EOF# 配置kubeletkubeadm alpha phase certs all --config kubeadm-master.configkubeadm alpha phase kubelet config write-to-disk --config kubeadm-master.configkubeadm alpha phase kubelet write-env-file --config kubeadm-master.configkubeadm alpha phase kubeconfig kubelet --config kubeadm-master.configsystemctl restart kubelet# 添加etcd到集群中KUBECONFIG=/etc/kubernetes/admin.conf kubectl exec -n kube-system etcd-$&#123;CP0_HOSTNAME&#125; -- etcdctl --ca-file /etc/kubernetes/pki/etcd/ca.crt --cert-file /etc/kubernetes/pki/etcd/peer.crt --key-file /etc/kubernetes/pki/etcd/peer.key --endpoints=https://$&#123;CP0_IP&#125;:2379 member add $&#123;CP2_HOSTNAME&#125; https://$&#123;CP2_IP&#125;:2380kubeadm alpha phase etcd local --config kubeadm-master.config# 部署kubeadm alpha phase kubeconfig all --config kubeadm-master.configkubeadm alpha phase controlplane all --config kubeadm-master.configkubeadm alpha phase mark-master --config kubeadm-master.config 4. 配置使用kubectl (在任意master节点操作)123456789101112rm -rf $HOME/.kubemkdir -p $HOME/.kubesudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/configsudo chown $(id -u):$(id -g) $HOME/.kube/config# 查看node节点kubectl get nodes# 只有网络插件也安装配置完成之后，才能会显示为ready状态# 设置master允许部署应用pod，参与工作负载，现在可以部署其他系统组件# 如 dashboard, heapster, efk等kubectl taint nodes --all node-role.kubernetes.io/master- 5. 配置网络插件 (在任意master节点操作)123curl -O https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.ymlkubectl apply -f kube-flannel.yml 6. 子节点加入集群 （所有子节点）就是你初始化第一个master保存的命令。1kubeadm join k8s.test.local:8443 --token bqnani.kwxe3y34vy22xnhm --discovery-token-ca-cert-hash sha256:b6146fea7a63d3a66e406c12f55f8d99537db99880409939e4aba206300e06cc 7. 查看节点状态1kubectl get nodes 返回如下：123456NAME STATUS ROLES AGE VERSIONk8s-master1 Ready master 49m v1.11.1k8s-master2 Ready master 47m v1.11.1k8s-master3 Ready master 45m v1.11.1k8s-slave1 Ready &lt;none&gt; 42m v1.11.1k8s-slave2 Ready &lt;none&gt; 42m v1.11.1 8. 配置k8s可视化没有Git请自行安装。 1234567# clone 配置文件git clone https://github.com/BrickCat/kubernetes-dashboard.git# 执行文件cd kubernetes-dashboardkubectl -n kube-system create -f . 配置角色文件1vim dashboard-admin.yaml 添加如下内容：1234567891011121314apiVersion: rbac.authorization.k8s.io/v1beta1kind: ClusterRoleBindingmetadata: name: kubernetes-dashboard labels: k8s-app: kubernetes-dashboardroleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: cluster-adminsubjects:- kind: ServiceAccount name: kubernetes-dashboard namespace: kube-system 1kubectl -f ./dashboard-admin.yaml create 9. 访问集群 http://192.168.1.111:30090","tags":[{"name":"kubernetes","slug":"kubernetes","permalink":"http://blog.githink.cn/tags/kubernetes/"},{"name":"docker","slug":"docker","permalink":"http://blog.githink.cn/tags/docker/"},{"name":"容器","slug":"容器","permalink":"http://blog.githink.cn/tags/容器/"},{"name":"k8s","slug":"k8s","permalink":"http://blog.githink.cn/tags/k8s/"}]},{"title":"Spring cloud config server 使用本地配置文件","date":"2018-02-09T14:32:36.000Z","path":"2018/02/09/Spring-cloud-config-server-使用本地配置文件/","text":"为了解决有的时候使用Git作为Config Server托管中心拉取配置失败的问题 学习Spring Cloud有一段时间了，今天在码云上看见一个非常不错的 Spring Cloud的项目 Pig ,功能十分强大，配套教程、文档也特别全。这么牛逼的项目不得down下来学习学习？于是clone下来，跟着视频安装好了各种环境，本以为万无一失的挨个启动就可以了。没想到启动到Config Server的时候并没有从Git服务器上拉取到配置信息。也去群里询问了，也问了作者 @冷冷 搞了半天也不行。后来觉得可能是公司的网管为了信息安全把一些端口给禁掉了，所有就想到把配置文件本地化了。 下面我们就来看看如何将配置文件本地化。 首先，我们先把配置文件从自己的Git服务器上拉取到本地。 12git clone https://gitee.com/cqzqxq_lxh/pig-config.gitgit checkout dev 然后，拉取Spring Cloud 项目。 1git clone https://gitee.com/log4j/pig.git 在pig-config模块下创建文件夹，把刚刚clone下来的配置文件拷贝到 properties文件夹中。 最后修改pig-config模块下的配置文件 application.yml。 注意：项目的启动腰包所有的配置文件的端口、Ip、用户名、密码之类的配置要改成自己的。 以上。","tags":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://blog.githink.cn/tags/Spring-Cloud/"}]},{"title":"axios post提交参数java后台接收不到参数解决办法","date":"2017-11-08T05:37:31.000Z","path":"2017/11/08/post传参/","text":"问题描述在浏览器中使用axiosPOST提交数据在后台接收的时候接收不到。 解决办法 首先我们先来了解一下什么是axios Axios 是一个基于 promise 的 HTTP 库，可以用在浏览器和 node.js 中。 问题原因 由于axios默认发送数据时，数据格式是Request Payload，而并非我们常用的Form Data格式，所以Java后台获取不到数据。在发送之前需要对数据进行处理。 解决办法12345678910var params = new URLSearchParams();params.append('firstName',Fred);axios.post('/user', params) .then(function (response) &#123; console.log(response); &#125;) .catch(function (error) &#123; console.log(error); &#125;);","tags":[{"name":"axios","slug":"axios","permalink":"http://blog.githink.cn/tags/axios/"},{"name":"javascript","slug":"javascript","permalink":"http://blog.githink.cn/tags/javascript/"},{"name":"常见问题","slug":"常见问题","permalink":"http://blog.githink.cn/tags/常见问题/"}]},{"title":"解决springboot-shiro-session设置过期时间无效的问题","date":"2017-10-30T06:19:19.000Z","path":"2017/10/30/springboot-shiro-session/","text":"问题描述在springboot整合shiro的时候session总是过期，往往是刚刚登录没一两分钟就又要重新登陆。网上查了很多资料说是可以设置session的过期时间server.session.timeout，无论你设置成多少都无效，后来才知道此session和shiro的session根本就是两回事。 解决办法下边我们就来看看在springboot中如何设置shiro的session过期时间。废话不多说直接上代码吧！ 1234567891011121314151617181920212223242526272829303132333435363738 /** * 添加session管理器 * @return */@Bean(name=\"sessionManager\")public DefaultWebSessionManager defaultWebSessionManager() &#123; System.out.println(\"ShiroConfiguration.defaultWebSessionManager()\"); DefaultWebSessionManager sessionManager = new DefaultWebSessionManager(); sessionManager.setCacheManager(cacheManager()); sessionManager.setSessionValidationInterval(3600000*12); sessionManager.setGlobalSessionTimeout(3600000*12); sessionManager.setDeleteInvalidSessions(true); sessionManager.setSessionValidationSchedulerEnabled(true); Cookie cookie = new SimpleCookie(ShiroHttpSession.DEFAULT_SESSION_ID_NAME); cookie.setName(\"ITBC\"); cookie.setHttpOnly(true); sessionManager.setSessionIdCookie(cookie); return sessionManager;&#125;/** * 用户授权信息Cache */ @Bean(name = \"shiroCacheManager\") @ConditionalOnMissingBean public CacheManager cacheManager() &#123; return new MemoryConstrainedCacheManager(); &#125; @Bean(name = \"securityManager\") @ConditionalOnMissingBean public DefaultSecurityManager securityManager() &#123; DefaultSecurityManager sm = new DefaultWebSecurityManager(); //添加缓存 sm.setCacheManager(cacheManager()); //添加session sm.setSessionManager(defaultWebSessionManager()); return sm; &#125; 后记其实在springboot的实际开发中博主遇到了很多坑，网上的解决办法也是零零碎碎的，总感觉不是自己想要的。有时间整理整理总结一下，发出来大家一起学习。","tags":[{"name":"常见问题","slug":"常见问题","permalink":"http://blog.githink.cn/tags/常见问题/"},{"name":"springboot","slug":"springboot","permalink":"http://blog.githink.cn/tags/springboot/"},{"name":"shiro","slug":"shiro","permalink":"http://blog.githink.cn/tags/shiro/"}]},{"title":"安装node以及npm学习ant-desgin","date":"2017-09-20T01:20:18.000Z","path":"2017/09/20/安装node以及npm学习ant-desgin/","text":"学习ant-desgin遇到的一些问题 在Mac上用brew安装的node.js,在使用npm时有些包是下载不下来的，导致项目编译失败。解决办法就是去官网下载LTS版本的node.js。 1、首先先把Mac上的npm下载的包删干净，然后在执行 brew uninstall node 参考 2、下载node.js 网址：https://nodejs.org/en/ 注意：下载LTS版本 3、进入到你项目的目录里，再次执行 npm i","tags":[{"name":"react","slug":"react","permalink":"http://blog.githink.cn/tags/react/"},{"name":"ant-desgin","slug":"ant-desgin","permalink":"http://blog.githink.cn/tags/ant-desgin/"},{"name":"dva","slug":"dva","permalink":"http://blog.githink.cn/tags/dva/"},{"name":"npm","slug":"npm","permalink":"http://blog.githink.cn/tags/npm/"},{"name":"node","slug":"node","permalink":"http://blog.githink.cn/tags/node/"}]},{"title":"安装 Semantic UI","date":"2017-09-02T15:43:05.000Z","path":"2017/09/02/Semantic UI/","text":"Semantic UI Semantic作为一款开发框架，帮助开发者使用对人类友好的HTML语言构建优雅的响应式布局。它还提供了一套很方便的定制主题的方法，你可以用自己的想法去改变界面组件的样式。在这个教程里我们学习一下安装 Semantic UI 。 准备工具 我们使用shell去安装semantic UI，前提是你已经安装好了nmp gulp。 开始安装 创建一个目录 12mkdir semanticcd semantic 用npm安装semantic UI 1npm install semantic-ui 一路回车就OK了。 查看是否安装成功1234├── node_modules├── package-lock.json├── semantic└── semantic.json 这是安装之后的文件夹和文件列表。 编译 进入到semantic的目录里（是安装完之后的semantic的目录） 然后执行 gulp 命令。 12 cd semantic gulp bulid 查看编译后的文件编译完之后会在文件夹中生成dist文件夹。 1dist gulpfile.js src tasks 现在到dist文件夹里看看都生成了什么东吧~ 12components semantic.js semantic.min.jssemantic.css semantic.min.css themes components 目录下面是单独的一些组件，如果你只想使用 Semantic UI 里的某些组件，可以在这个目录下面找到这些组件。如果你想使用全部的组件，可以使用 semantic.css 与 semantic.js ，或者使用它们的最小化之后的版本，semanitc.min.css 与 semantic.min.js 。 themes 目录下是主题的样式，现在主要有四种主题:1basic default github material 修改主题只需要进入到src文件夹中修改theme.config文件即可。例如把default换成github。","tags":[{"name":"Semantic UI","slug":"Semantic-UI","permalink":"http://blog.githink.cn/tags/Semantic-UI/"}]},{"title":"windows 搭建Git服务器","date":"2017-08-31T03:42:59.000Z","path":"2017/08/31/windows搭建Git服务器/","text":"初衷 由于在GitHub上的私有项目是付费的，并且用GitHub Pages 搭建Hexo博客有的时候慢的真的想砸了电脑。所以就想自己搭建一个Git服务器，用于放一些私有项目和搭建一个Hexo博客。 下面就跟着我一起来用最简单的方法搭建Git服务器吧~ 下载相关软件 gitstack 安装 下载完后双击就可以，安装的过程中是默认用80端口的，先把占用80端口的进程Kill掉。重新启动程序。一路下一步就好。安装的过程中也可以自定义安装目录。安装完成后在浏览器中输入http://localhost/gitstack就可以访问了，默认用户名密码是admin/admin。 配置基本配置 修改密码：在Settings-&gt;general-&gt;Administrator password中修改默认的密码。 修改端口：在Settings-&gt;general-&gt;Server Ports中修改端口号，后续访问的话就是IP地址加端口号访问。 修改仓库地址：Settings-&gt;general-&gt;Repositories Location中修改该地址。 添加用户和组 添加用户 添加组 创建Repositories 给Repositories加用户 创建完Repositories要给它添加用户的，否则访问不了。注意：管理员账户并不能访问这个Repositories。 最后 git clone 你创建的Repositories，提示你输入用户名密码，就能把项目clone下来。 预告搭建不依赖于GitHub Pages 的 Hexo 博客。","tags":[{"name":"Git","slug":"Git","permalink":"http://blog.githink.cn/tags/Git/"},{"name":"server","slug":"server","permalink":"http://blog.githink.cn/tags/server/"}]},{"title":"windows搭建流媒体服务器","date":"2017-08-30T03:42:59.000Z","path":"2017/08/30/windows搭建流媒体服务器/","text":"理论什么是流媒体服务器 流媒体指以流方式在网络中传送音频、视频和多媒体文件的媒体形式。相对于下载后观看的网络播放形式而言，流媒体的典型特征是把连续的音频和视频信息压缩后放到网络服务器上，用户边下载边观看，而不必等待整个文件下载完毕。由于流媒体技术的优越性，该技术广泛应用于视频点播、视频会议、远程教育、远程医疗和在线直播系统中。 作为新一代互联网应用的标志，流媒体技术在近几年得到了飞速的发展。流媒体服务器是流媒体应用的核心系统，是运营商向用户提供视频服务的关键平台。流媒体服务器的主要功能是对流媒体内容进行采集、缓存、调度和传输播放。流媒体应用系统的主要性能体现都取决于媒体服务器的性能和服务质量。因此，流媒体服务器是流媒体应用系统的基础，也是最主要的组成部分。 什么是HLS (HTTP Live Streaming) 常用的流媒体协议主要有 HTTP 渐进下载和基于 RTSP/RTP 的实时流媒体协议，这二种基本是完全不同的东西，目前比较方便又好用的是用 HTTP 渐进下载方法。在这个中 apple 公司的 HTTP Live Streaming 是这个方面的代表。它最初是苹果公司针对iPhone、iPod、iTouch和iPad等移动设备而开发的流.现在见到在桌面也有很多应用了，HTML5 是直接支持这个。但是HLS协议的小切片方式会生成大量的文件，存储或处理这些文件会造成大量资源浪费。如果要实现数天的时移，索引量将会是个巨额数字，并明显影响请求速度。因此，HLS协议对存储I/O要求相当苛刻。对此，也有公司提出了非常好的解决方案。 新型点播服务器系统，独创了内存缓存数据实时切片技术，颠覆了这种传统实现方法，从根本上解决了大量切片的碎片问题，使得单台服务器的切片与打包能力不再是瓶颈。其基本原理如下： 不将TS切片文件存到磁盘，而是存在内存当中，这种技术使得服务器的磁盘上面不再会有“数以吨计”的文件碎片，极大减少了磁盘的I/O次数，延长了服务器磁盘的使用寿命，极大提高了服务器运行的稳定性。同时，由于使用这种技术，使得终端请求数据时直接从服务器的内存中获取，极大提高了对终端数据请求的反应速度，优化了视频观看体验。 什么是FFmpeg FFmpeg是一套可以用来记录、转换数字音频、视频，并能将其转化为流的开源计算机程序。采用LGPL或GPL许可证。它提供了录制、转换以及流化音视频的完整解决方案。它包含了非常先进的音频/视频编解码库libavcodec，为了保证高可移植性和编解码质量，libavcodec里很多code都是从头开发的。 什么是Nginx Nginx (engine x) 是一个高性能的HTTP和反向代理服务器，也是一个IMAP/POP3/SMTP服务器。 实践安装 JAVA环境不在这里赘述，自行百度。博主这里是Windows server 2012的环境，后续会出Mac、Linux环境的教程。 安装NginxNginx-1.12.0 stable 查看Nginx的版本号：nginx -v 启动Nginx: cd 安装目录 ，start nginx 快速停止或关闭Nginx：nginx -s stop 正常停止或关闭Nginx：nginx -s quit 配置文件修改重装载命令：nginx -s reload 安装FFmpegFFmpeg 根据自己的操作系统选择下载最新的32位或64位静态程序版本。 配置配置nginx 博主感觉Nginx真的是一个好东西，能做点播服务器、直播服务器、文件服务器、负载均衡等等一些牛逼的功能。深入了解只有不得不佩服它的的强大。下面就跟着博主一起去见识一下Nginx吧（后续博主会写Nginx配置https和wss以及一个IP绑定多个域名等）。 直接解压缩就好了，windows下直接点击nginx.exe就可以启动Nginx，在浏览器里访问http://localhost就可以看到Nigix的欢迎页面。由于Nginx默认使用80端口可能会被占用。你要先kill掉占用80端口的进程。 在conf文件夹中打开mine.types文件。 在application/zip zip;后面加上如下两行： 12application/x-mpegURL m3u8; application/vnd.apple.mpegurl m3u8; 然后在video/x-msvideo avi;添加video/MP2T ts; 打开nginx.conf文件，（最好先备份一下） 下面就是如何配置Nginx的代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134#user nobody;worker_processes 1;#要开启的进程数 一般等于cpu的总核数 其实一般情况下开4个或8个就可 我开2个#error_log logs/error.log;#error_log logs/error.log notice;#error_log logs/error.log info;#pid logs/nginx.pid;events &#123; worker_connections 1024;#默认最大的并发数为1024，如果你的网站访问量过大，已经远远超过1024这个并发数，那你就要修改worker_connecions这个值 ，这个值越大，并发数也有就大。当然，你一定要按照你自己的实际情况而定，也不能设置太大，不能让你的CPU跑满100%。&#125;http &#123; include mime.types; #解决Nginx跨域访问 Begin default_type application/octet-stream; add_header Cache-Control no-cache; add_header 'Access-Control-Allow-Origin' '*' always; add_header 'Access-Control-Expose-Headers' 'Content-Length,Content-Range'; add_header 'Access-Control-Allow-Headers' 'Range'; #解决Nginx跨域访问 End #log_format main '$remote_addr - $remote_user [$time_local] \"$request\" ' # '$status $body_bytes_sent \"$http_referer\" ' # '\"$http_user_agent\" \"$http_x_forwarded_for\"'; #access_log logs/access.log main; sendfile on; #tcp_nopush on; #keepalive_timeout 0; keepalive_timeout 65; #gzip on; server &#123; listen 8080;#监听的的端口默认是80 server_name localhost;#默认就行 #charset koi8-r; #access_log logs/host.access.log main; #请求路径 / location / &#123; #设置HTTP Response的Content-Type types&#123; application/vnd.apple.mpegurl m3u8; video/MP2T ts; &#125; #指定访问的根目录，也是放你视频切片文件的地方，不用配置可直接访问 如：http://localhost:8080/playList.m3u8 root html; &#125; #访问.mp4格式的文件 location ~ .mp4 &#123; mp4; &#125; #error_page 404 /404.html; # redirect server error pages to the static page /50x.html # error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125; # proxy the PHP scripts to Apache listening on 127.0.0.1:80 # #location ~ \\.php$ &#123; # proxy_pass http://127.0.0.1; #&#125; # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000 # #location ~ \\.php$ &#123; # root html; # fastcgi_pass 127.0.0.1:9000; # fastcgi_index index.php; # fastcgi_param SCRIPT_FILENAME /scripts$fastcgi_script_name; # include fastcgi_params; #&#125; # deny access to .htaccess files, if Apache's document root # concurs with nginx's one # #location ~ /\\.ht &#123; # deny all; #&#125; &#125; # another virtual host using mix of IP-, name-, and port-based configuration # #server &#123; # listen 8000; # listen somename:8080; # server_name somename alias another.alias; # location / &#123; # root html; # index index.html index.htm; # &#125; #&#125; # HTTPS server # #server &#123; # listen 443 ssl; # server_name localhost; # ssl_certificate cert.pem; # ssl_certificate_key cert.key; # ssl_session_cache shared:SSL:1m; # ssl_session_timeout 5m; # ssl_ciphers HIGH:!aNULL:!MD5; # ssl_prefer_server_ciphers on; # location / &#123; # root html; # index index.html index.htm; # &#125; #&#125; &#125; 到这里Nginx全部配置完成。 配置FFmpeg配置环境变量 解压缩后它会生成一个类似名为“ffmpeg-20150504-Git-eb9fb50-win32-static”的新文件夹，重命名为ffmpeg 配置 配置环境变量点击“开始菜单”，再点击“控制面板”，再点击“系统与安全”，再点击“系统”，然后点击“高级系统设置”，跳出“系统属性”窗口后，最后点击“环境变量”按钮：点击“环境变量”按钮后，跳出“环境变量”窗口，找到并选中“Path”变量，点击编辑：在“Path”变量原有变量值内容上加上“;d:\\ffmpeg\\bin”（注：;代表间隔，不可遗漏；d:\\ffmpeg\\bin代表FFmpeg的安装路径下的bin文件夹），一路点击“确定”即可。打开命令提示符窗口。输入命令“ffmpeg –version”。如果命令提示窗口返回FFmpeg的版本信息，那么就说明安装成功了，你可以在命令提示行中任意文件夹下运行FFmpeg。 视频切片与访问 命令： 1ffmpeg -i output.mp4 -c:v libx264 -c:a aac -strict -2 -f hls -hls_list_size 0 -hls_time 5 output.m3u8 输入与输出的文件都可以添加路径。如：ffmpeg -i C:\\Users\\Desktop\\output.mp4 -c:v libx264 -c:a aac -strict -2 -f hls -hls_list_size 0 -hls_time 5 C:\\Users\\Desktop\\nginx-1.12.0\\html\\output.m3u8-hls_list_size n:设置播放列表保存的最多条目，设置为0会保存有所片信息，默认值为5。-hls_time n: 设置每片的长度，默认值为2。单位为秒。 查看下载VLC media player打开本地文件output.m3u8,如果能播放表示切片成功。 Nginx结合FFmpeg 大体思路就是把视频切片到指定位置，用nginx去代理你这个位置，就可以了。 一 把nginx文件里的html文件夹下的所有文件都删除。新建一个m3u8的文件夹。 二 把切片命令的输出地址换成你的m3u8文件夹所在的位置。 三 启动Nginx,在VLC中输入http://localhost:8080/m3u8/output.m3u8（nginx监听的8080端口） 预告 如何用Webuploader上传大文件视频，并用FFmpeg切片，Nginx代理文件，html播放。","tags":[{"name":"server","slug":"server","permalink":"http://blog.githink.cn/tags/server/"},{"name":"nginx","slug":"nginx","permalink":"http://blog.githink.cn/tags/nginx/"},{"name":"ffmpeg","slug":"ffmpeg","permalink":"http://blog.githink.cn/tags/ffmpeg/"},{"name":"hls","slug":"hls","permalink":"http://blog.githink.cn/tags/hls/"}]}]